#!/usr/bin/env python3
"""
Enhanced Data Generators for LimeSurvey Testing

Creates realistic synthetic data based on analysis of real survey data:
- Real survey: 291558 with 359 responses, 62 questions, 11 question types
- Enhanced to match observed patterns and data structures

Key improvements over original generator:
1. More question types (11 vs 6) 
2. Realistic survey metadata (properties, summary, groups)
3. Complex response column patterns (121 columns)
4. Variable option counts (185 total options across questions)
5. Real-world distributions and missing data patterns
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import random
from datetime import datetime, timedelta
import json


@dataclass
class MockSurveyProperties:
    """Mock survey properties matching real LimeSurvey format"""
    sid: str  # Survey IDs are strings, not integers
    admin: str
    active: str  # Y/N
    language: str
    datecreated: str
    anonymized: str  # Y/N
    format: int
    template: str
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary format like real API"""
        return {
            'sid': self.sid,
            'admin': self.admin,
            'active': self.active,
            'language': self.language,
            'additional_languages': '',
            'datecreated': self.datecreated,
            'anonymized': self.anonymized,
            'format': self.format,
            'template': self.template,
            'expires': '',
            'startdate': '',
            'adminemail': 'admin@example.com',
            'datestamp': 'Y',
            'usecookie': 'N',
            'allowregister': 'N',
            'allowsave': 'Y',
            'autoredirect': 'N',
            'allowprev': 'Y',
            'printanswers': 'N',
            'ipaddr': 'N',
            'refurl': 'N',
            'showwelcome': 'Y',
            'showprogress': 'Y',
            'questionindex': 0,
            'navigationdelay': 0,
            'nokeyboard': 'N'
        }


@dataclass
class MockSurveySummary:
    """Mock survey summary matching real format"""
    completed_responses: int
    incomplete_responses: int
    full_responses: int
    
    def to_dict(self) -> Dict[str, int]:
        return {
            'completed_responses': self.completed_responses,
            'incomplete_responses': self.incomplete_responses,
            'full_responses': self.full_responses
        }


class EnhancedSurveyDataGenerator:
    """
    Enhanced generator based on real survey analysis.
    
    Real data patterns observed:
    - 62 questions across 11 types: listradio(16), ranking(8), shortfreetext(5), 
      longfreetext(2), numerical(1), multipleshorttext(1), equation(1), 
      image_select-listradio(1), multiplechoice(1), arrays/increasesamedecrease(1), 
      image_select-multiplechoice(1)
    - 359 completed responses, 655 total (45% completion rate)
    - 121 response columns with complex patterns
    - 185 option records across all questions
    """
    
    def __init__(self, survey_id: str = "111111", 
                 completed_responses: int = 359,
                 incomplete_responses: int = 296):
        self.survey_id = survey_id
        self.completed_responses = completed_responses
        self.incomplete_responses = incomplete_responses
        self.total_responses = completed_responses + incomplete_responses
        
        # Real question type distribution
        self.question_type_counts = {
            'listradio': 16,
            'ranking': 8, 
            'shortfreetext': 5,
            'longfreetext': 2,
            'numerical': 1,
            'multipleshorttext': 1,
            'equation': 1,
            'image_select-listradio': 1,
            'multiplechoice': 1,
            'arrays/increasesamedecrease': 1,
            'image_select-multiplechoice': 1
        }
        
        # Realistic demographic patterns from real data
        self.demographic_patterns = {
            'age_brackets': ['18-25', '26-35', '36-45', '46-55', '56-65', '65+'],
            'education_levels': ['High School', 'Bachelor', 'Master', 'PhD', 'Other'],
            'employment_status': ['Employed', 'Unemployed', 'Student', 'Retired', 'Self-employed']
        }
        
        # Response completion patterns (observed: 55% completion rate)
        self.completion_probability = 0.55
        
    def generate_survey_properties(self) -> Dict[str, Any]:
        """Generate survey properties matching real API format"""
        props = MockSurveyProperties(
            sid=str(self.survey_id),  # Keep survey ID as string
            admin='testadmin',
            active='Y',
            language='en',
            datecreated=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            anonymized='Y',
            format=1,
            template='default'
        )
        return props.to_dict()
    
    def generate_survey_summary(self) -> Dict[str, int]:
        """Generate survey summary matching real format"""
        summary = MockSurveySummary(
            completed_responses=self.completed_responses,
            incomplete_responses=self.incomplete_responses,
            full_responses=self.total_responses
        )
        return summary.to_dict()
    
    def generate_groups_data(self) -> List[Dict[str, Any]]:
        """Generate realistic group data"""
        return [
            {
                'gid': '1',
                'group_name': 'Demographics',
                'group_order': 1,
                'description': 'Demographic questions',
                'language': 'en',
                'randomization_group': '',
                'grelevance': '1'
            },
            {
                'gid': '2', 
                'group_name': 'Main Survey',
                'group_order': 2,
                'description': 'Main survey questions',
                'language': 'en',
                'randomization_group': '',
                'grelevance': '1'
            },
            {
                'gid': '3',
                'group_name': 'Feedback',
                'group_order': 3,
                'description': 'Additional feedback',
                'language': 'en',
                'randomization_group': '',
                'grelevance': '1'
            }
        ]
    
    def generate_realistic_questions_dataframe(self) -> pd.DataFrame:
        """Generate questions DataFrame matching real data structure"""
        questions = []
        question_counter = 1
        
        for q_type, count in self.question_type_counts.items():
            for i in range(count):
                qid = f"{100 + question_counter}"
                
                if q_type == 'listradio':
                    title = f"Q{question_counter:02d}"
                    question_text = f"Rate your satisfaction with aspect {i+1}"
                elif q_type == 'ranking':
                    title = f"RANK{i+1:02d}"
                    question_text = f"Rank these priorities (set {i+1})"
                elif q_type == 'shortfreetext':
                    title = f"TEXT{i+1:02d}"
                    question_text = f"Please provide your input for {i+1}"
                elif q_type == 'longfreetext':
                    title = f"ESSAY{i+1:02d}"
                    question_text = f"Please provide detailed feedback about {i+1}"
                elif q_type == 'numerical':
                    title = f"NUM{i+1:02d}"
                    question_text = f"Enter numeric value for {i+1}"
                elif q_type == 'multipleshorttext':
                    title = f"MST{i+1:02d}"
                    question_text = f"Contact information {i+1}"
                elif q_type == 'equation':
                    title = f"EQ{i+1:02d}"
                    question_text = f"Calculation {i+1}"
                elif q_type == 'multiplechoice':
                    title = f"MC{i+1:02d}"
                    question_text = f"Select all that apply {i+1}"
                elif q_type.startswith('image_select'):
                    title = f"IMG{i+1:02d}"
                    question_text = f"Select from images {i+1}"
                elif q_type.startswith('arrays'):
                    title = f"ARR{i+1:02d}"
                    question_text = f"Rate changes in {i+1}"
                else:
                    title = f"Q{question_counter:02d}"
                    question_text = f"Question {question_counter}"
                
                questions.append({
                    'id': qid,
                    'question': question_text,
                    'help': '',
                    'language': 'en',
                    'qid': qid,
                    'parent_qid': '0',
                    'sid': str(self.survey_id),  # Keep survey ID as string
                    'type': self._get_limesurvey_type_code(q_type),
                    'title': title,
                    'preg': '',
                    'other': 'N',
                    'mandatory': random.choice(['Y', 'N']),
                    'encrypted': 'N',
                    'question_order': question_counter,
                    'scale_id': 0,
                    'same_default': 0,
                    'question_theme_name': q_type,
                    'modulename': '',
                    'gid': random.choice([1, 2, 3]),
                    'relevance': '1',
                    'same_script': 0
                })
                
                question_counter += 1
        
        return pd.DataFrame(questions)
    
    def _get_limesurvey_type_code(self, theme_name: str) -> str:
        """Convert theme name to LimeSurvey type code"""
        mapping = {
            'listradio': 'L',
            'ranking': 'R', 
            'shortfreetext': 'S',
            'longfreetext': 'T',
            'numerical': 'N',
            'multipleshorttext': 'Q',
            'equation': '*',
            'image_select-listradio': 'L',
            'multiplechoice': 'M',
            'arrays/increasesamedecrease': 'A',
            'image_select-multiplechoice': 'M'
        }
        return mapping.get(theme_name, 'T')
    
    def generate_realistic_options_dataframe(self, questions_df: pd.DataFrame) -> pd.DataFrame:
        """Generate options DataFrame with realistic variety (target: ~185 total options)"""
        options = []
        
        for _, question in questions_df.iterrows():
            qid = question['qid']
            question_code = question['title']
            theme = question['question_theme_name']
            
            if theme in ['listradio', 'image_select-listradio']:
                # 3-7 options per question (realistic variety)
                num_options = random.randint(3, 7)
                for i in range(num_options):
                    options.append({
                        'option_code': str(i+1),
                        'answer': self._get_realistic_option_text(theme, i),
                        'assessment_value': str(i+1),
                        'scale_id': 0,
                        'option_order': i+1,
                        'qid': qid,
                        'question_code': question_code
                    })
            
            elif theme == 'ranking':
                # Ranking questions typically have 4-6 items to rank
                num_items = random.randint(4, 6)
                items = self._get_ranking_items()[:num_items]
                for i, item in enumerate(items):
                    options.append({
                        'option_code': chr(65 + i),  # A, B, C, D...
                        'answer': item,
                        'assessment_value': str(i+1),
                        'scale_id': 0,
                        'option_order': i+1,
                        'qid': qid,
                        'question_code': question_code
                    })
            
            # Other question types don't typically have predefined options
        
        return pd.DataFrame(options)
    
    def _get_realistic_option_text(self, theme: str, index: int) -> str:
        """Generate realistic option text"""
        if theme in ['listradio', 'image_select-listradio']:
            satisfaction_options = [
                'Very Dissatisfied', 'Dissatisfied', 'Neutral', 
                'Satisfied', 'Very Satisfied', 'Extremely Satisfied', 'Not Applicable'
            ]
            agreement_options = [
                'Strongly Disagree', 'Disagree', 'Neutral',
                'Agree', 'Strongly Agree', 'Not Sure', 'Prefer not to answer'
            ]
            frequency_options = [
                'Never', 'Rarely', 'Sometimes', 'Often', 'Always', 'Not Applicable'
            ]
            
            option_sets = [satisfaction_options, agreement_options, frequency_options]
            selected_set = random.choice(option_sets)
            return selected_set[index % len(selected_set)]
        
        return f"Option {index + 1}"
    
    def _get_ranking_items(self) -> List[str]:
        """Get realistic items for ranking questions"""
        return [
            'Quality', 'Price', 'Speed', 'Customer Service', 'Reliability',
            'Innovation', 'Convenience', 'Brand Reputation', 'Features', 'Support'
        ]
    
    def generate_realistic_responses(self, questions_df: pd.DataFrame, 
                                   options_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Generate realistic response data matching observed patterns (121 columns)"""
        
        # Generate response metadata (matches real format)
        metadata_data = {
            'id': [f"R{i+1}" for i in range(self.total_responses)],
            'submitdate': self._generate_submit_dates(),
            'lastpage': self._generate_last_pages(),
            'startlanguage': ['en'] * self.total_responses,
            'seed': [random.randint(1000000, 9999999) for _ in range(self.total_responses)],
            'startdate': self._generate_start_dates(),
            'datestamp': self._generate_date_stamps(),
            'refurl': [''] * self.total_responses
        }
        responses_metadata = pd.DataFrame(metadata_data)
        
        # Generate user input responses
        user_input_data = {'id': [f"R{i+1}" for i in range(self.completed_responses)]}
        
        for _, question in questions_df.iterrows():
            qid = question['qid']
            question_code = question['title']
            theme = question['question_theme_name']
            
            if theme in ['listradio', 'image_select-listradio']:
                user_input_data[question_code] = self._generate_radio_responses(qid, options_df)
                
            elif theme == 'ranking':
                # Ranking generates multiple columns (one per rank position)
                max_ranks = len(options_df[options_df['qid'] == qid])
                for rank in range(1, max_ranks + 1):
                    col_name = f"{question_code}[{rank}]"
                    user_input_data[col_name] = self._generate_ranking_responses(qid, rank, options_df)
                    
            elif theme == 'multiplechoice':
                # Multiple choice generates Y/N columns for each option
                num_options = random.randint(3, 6)
                for i in range(num_options):
                    col_name = f"{question_code}[SQ{i+1:03d}]"
                    user_input_data[col_name] = self._generate_multiple_choice_responses()
                    
            elif theme == 'image_select-multiplechoice':
                # Image select multiple choice works like regular multiple choice
                num_options = random.randint(3, 6)
                for i in range(num_options):
                    col_name = f"{question_code}[SQ{i+1:03d}]"
                    user_input_data[col_name] = self._generate_multiple_choice_responses()
                    
            elif theme == 'equation':
                # Equation questions work like radio buttons - single selection
                user_input_data[question_code] = self._generate_radio_responses(qid, options_df)
                    
            elif theme == 'multipleshorttext':
                # Multiple short text generates columns for each sub-question
                sub_questions = ['Name', 'Email', 'Phone', 'Address']
                for i, sub_q in enumerate(sub_questions):
                    col_name = f"{question_code}[SQ{i+1:03d}]"
                    user_input_data[col_name] = self._generate_text_responses(short=True)
                    
            elif theme in ['shortfreetext', 'longfreetext', 'numerical']:
                user_input_data[question_code] = self._generate_text_responses(
                    short=(theme == 'shortfreetext'))
                    
            elif theme == 'arrays/increasesamedecrease':
                # Array questions generate matrix-style responses
                sub_items = ['Item A', 'Item B', 'Item C']
                for i, item in enumerate(sub_items):
                    col_name = f"{question_code}[SQ{i+1:03d}]"
                    user_input_data[col_name] = self._generate_array_responses()
        
        # Add demographic-style questions to reach ~121 columns
        self._add_demographic_columns(user_input_data)
        
        responses_user_input = pd.DataFrame(user_input_data)
        
        return responses_user_input, responses_metadata
    
    def _generate_radio_responses(self, qid: str, options_df: pd.DataFrame) -> List[str]:
        """Generate realistic radio button responses"""
        question_options = options_df[options_df['qid'] == qid]['option_code'].tolist()
        if not question_options:
            question_options = ['1', '2', '3', '4', '5']
        
        # Realistic distribution (slightly positive skew)
        responses = []
        for _ in range(self.completed_responses):
            if random.random() < 0.95:  # 5% missing
                responses.append(np.random.choice(question_options))
            else:
                responses.append('')
        return responses
    
    def _generate_ranking_responses(self, qid: str, rank_position: int, 
                                  options_df: pd.DataFrame) -> List[str]:
        """Generate realistic ranking responses"""
        available_codes = options_df[options_df['qid'] == qid]['option_code'].tolist()
        if not available_codes:
            available_codes = ['A', 'B', 'C', 'D']
        
        responses = []
        for _ in range(self.completed_responses):
            completion_rate = 0.85 - (rank_position - 1) * 0.1  # Decreasing completion by rank
            if random.random() < completion_rate:
                responses.append(random.choice(available_codes))
            else:
                responses.append('')
        return responses
    
    def _generate_multiple_choice_responses(self) -> List[str]:
        """Generate Y/N responses for multiple choice options"""
        responses = []
        selection_prob = random.uniform(0.15, 0.45)  # 15-45% select each option
        for _ in range(self.completed_responses):
            if random.random() < selection_prob:
                responses.append('Y')
            else:
                responses.append('')
        return responses
    
    def _generate_text_responses(self, short: bool = True) -> List[str]:
        """Generate realistic text responses"""
        if short:
            sample_responses = [
                'Good', 'Excellent', 'Needs improvement', 'Satisfactory', 
                'Very good', 'Poor', 'Outstanding', 'Average', ''
            ]
        else:
            sample_responses = [
                'This is a detailed response with multiple sentences.',
                'I think this could be improved in several ways.',
                'Overall very satisfied with the experience.',
                'No additional comments at this time.',
                'Excellent service and would recommend to others.',
                '', '', ''  # More missing for long text
            ]
        
        return [random.choice(sample_responses) for _ in range(self.completed_responses)]
    
    def _generate_array_responses(self) -> List[str]:
        """Generate Increase/Same/Decrease responses"""
        choices = ['I', 'S', 'D', '']  # Increase, Same, Decrease, Missing
        probabilities = [0.3, 0.4, 0.2, 0.1]
        return [np.random.choice(choices, p=probabilities) for _ in range(self.completed_responses)]
    
    def _add_demographic_columns(self, user_input_data: Dict[str, List]):
        """Add demographic columns to reach target of ~121 columns"""
        # Add typical demographic patterns
        user_input_data['DEM01'] = [random.choice(['M', 'F', 'O', '']) 
                                  for _ in range(self.completed_responses)]
        user_input_data['DEM02'] = [random.randint(18, 75) if random.random() < 0.95 else '' 
                                  for _ in range(self.completed_responses)]
        user_input_data['DEM02HiddenAgeBrack'] = [
            random.choice(self.demographic_patterns['age_brackets']) 
            for _ in range(self.completed_responses)
        ]
        user_input_data['DEM03'] = [
            random.choice(self.demographic_patterns['education_levels']) 
            for _ in range(self.completed_responses)
        ]
        user_input_data['DEM03[other]'] = ['' for _ in range(self.completed_responses)]
        
        # Add location questions similar to real data
        for i in range(1, 6):
            user_input_data[f'DEM04[SQ{i:03d}]'] = [
                random.choice(['Urban', 'Suburban', 'Rural', ''])
                for _ in range(self.completed_responses)
            ]
        
        user_input_data['DEM05'] = [random.choice(self.demographic_patterns['employment_status'])
                                   for _ in range(self.completed_responses)]
        user_input_data['DEM06SreenAreaReside'] = [
            random.choice(['North', 'South', 'East', 'West', 'Central'])
            for _ in range(self.completed_responses)
        ]
    
    def _generate_submit_dates(self) -> List[Optional[str]]:
        """Generate submit dates (None for incomplete responses)"""
        dates = []
        base_date = datetime.now() - timedelta(days=30)
        
        for i in range(self.total_responses):
            if i < self.completed_responses:  # Completed responses have submit dates
                random_offset = timedelta(days=random.randint(0, 30), 
                                        hours=random.randint(0, 23))
                submit_date = base_date + random_offset
                dates.append(submit_date.strftime('%Y-%m-%d %H:%M:%S'))
            else:  # Incomplete responses have no submit date
                dates.append(None)
        
        return dates
    
    def _generate_last_pages(self) -> List[int]:
        """Generate last page numbers"""
        pages = []
        for i in range(self.total_responses):
            if i < self.completed_responses:
                pages.append(3)  # Completed all pages
            else:
                pages.append(random.randint(1, 2))  # Stopped early
        return pages
    
    def _generate_start_dates(self) -> List[str]:
        """Generate start dates for all responses"""
        dates = []
        base_date = datetime.now() - timedelta(days=30)
        
        for _ in range(self.total_responses):
            random_offset = timedelta(days=random.randint(0, 30), 
                                    hours=random.randint(0, 23))
            start_date = base_date + random_offset
            dates.append(start_date.strftime('%Y-%m-%d %H:%M:%S'))
        
        return dates
    
    def _generate_date_stamps(self) -> List[str]:
        """Generate date stamps for all responses"""
        return self._generate_start_dates()  # Same pattern as start dates
    
    def generate_complete_survey_dataset(self) -> Dict[str, Any]:
        """Generate complete survey dataset matching real data patterns"""
        
        # Generate all components
        properties = self.generate_survey_properties()
        summary = self.generate_survey_summary()
        groups = self.generate_groups_data()
        questions_df = self.generate_realistic_questions_dataframe()
        options_df = self.generate_realistic_options_dataframe(questions_df)
        responses_user_input, responses_metadata = self.generate_realistic_responses(
            questions_df, options_df)
        
        return {
            'properties': properties,
            'summary': summary,
            'groups': groups,
            'questions': questions_df,
            'options': options_df,
            'responses_user_input': responses_user_input,
            'responses_metadata': responses_metadata,
            'survey_id': self.survey_id
        }


def create_enhanced_test_data(survey_id: str = "111111") -> Dict[str, Any]:
    """
    Create enhanced test data matching real survey patterns.
    
    Returns complete dataset with all components needed for testing.
    """
    generator = EnhancedSurveyDataGenerator(survey_id)
    return generator.generate_complete_survey_dataset()


if __name__ == "__main__":
    # Generate sample data and show summary
    print("ðŸš€ Generating enhanced survey test data...")
    data = create_enhanced_test_data()
    
    print(f"\nðŸ“Š Generated Survey Dataset Summary:")
    print(f"   Survey ID: {data['survey_id']}")
    print(f"   Questions: {data['questions'].shape[0]} ({len(data['questions']['question_theme_name'].unique())} types)")
    print(f"   Options: {data['options'].shape[0]} total")
    print(f"   Responses: {data['responses_user_input'].shape[0]} completed")
    print(f"   Response columns: {data['responses_user_input'].shape[1]}")
    print(f"   Metadata: {data['responses_metadata'].shape[0]} total (including incomplete)")
    
    print(f"\nðŸŽ¯ Question type distribution:")
    for q_type, count in data['questions']['question_theme_name'].value_counts().items():
        print(f"   {q_type}: {count}")
    
    print(f"\nâœ… Enhanced generator ready for testing!") 